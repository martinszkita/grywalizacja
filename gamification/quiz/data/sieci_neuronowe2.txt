W sieciach neuronowych coraz częściej wykorzystuje się techniki uczenia samo­nadzorowanego, które pozwalają modelom uczyć się struktury danych bez ręcznie przygotowanych etykiet, co znacząco skraca czas przygotowania zbiorów treningowych. Coraz większe znaczenie zyskują także modele hybrydowe łączące logikę symboliczną z sieciami neuronowymi, dzięki czemu systemy mogą nie tylko uczyć się wzorców, ale też operować jawną wiedzą. W badaniach eksperymentalnych stosuje się sieci kapsułkowe, które lepiej odwzorowują zależności przestrzenne w obrazach i radzą sobie z rozpoznawaniem obiektów pod różnymi kątami. W dziedzinie optymalizacji rośnie popularność metod adaptacyjnych, takich jak AdamW, które stabilizują proces uczenia przy bardzo dużych sieciach. Nowe techniki regularizacji pozwalają modelom lepiej generalizować, nawet gdy dane są niejednorodne lub zebrane w różnych warunkach. W praktyce przemysłowej sieci neuronowe coraz częściej działają na urządzeniach brzegowych, co umożliwia analizę danych w czasie rzeczywistym bez konieczności wysyłania ich do chmury. W zastosowaniach robotycznych stosuje się modele uczące się przez wzmacnianie, które adaptują zachowanie maszyn w dynamicznych środowiskach. Jednym z kierunków rozwoju jest również uczenie federacyjne, dzięki któremu sieci mogą trenować na rozproszonych urządzeniach bez naruszania prywatności użytkowników. Pojawiają się też modele wielomodalne, które potrafią jednocześnie analizować obrazy, tekst, audio i dane sensoryczne, tworząc spójne reprezentacje świata. Badacze rozwijają również nowe metody kompresji modeli, aby zmniejszać ich rozmiar bez drastycznej utraty jakości, co jest kluczowe w zastosowaniach mobilnych i embedded.